{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import onnx\n",
    "from onnx.tools import update_model_dims\n",
    "import numpy as np\n",
    "import onnx.helper as helper\n",
    "from onnx import shape_inference, TensorProto\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from pathlib import Path\n",
    "from transformers.convert_graph_to_onnx import convert"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1424,  0.1335, -0.1291,  ..., -0.3597, -0.0562,  0.3605],\n",
      "         [-0.3506,  0.1042,  0.6244,  ..., -0.1761,  0.4834,  0.0644],\n",
      "         [-0.2451, -0.1573,  0.6945,  ..., -0.5654, -0.0894, -0.1856],\n",
      "         [-0.8248, -0.9119, -0.6561,  ...,  0.5074, -0.1939, -0.1659],\n",
      "         [ 0.8767,  0.0352, -0.1233,  ...,  0.2720, -0.6369, -0.1585]]],\n",
      "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-8.9756e-01, -3.3040e-01, -7.6942e-01,  7.5799e-01,  4.6678e-01,\n",
      "         -1.2035e-01,  9.1835e-01,  1.8087e-01, -7.2716e-01, -9.9991e-01,\n",
      "         -4.4723e-01,  8.9104e-01,  9.6621e-01,  5.4915e-01,  9.4344e-01,\n",
      "         -7.6605e-01, -6.0469e-01, -6.1654e-01,  4.0572e-01, -7.4644e-01,\n",
      "          6.1739e-01,  9.9974e-01,  3.2990e-02,  2.5414e-01,  4.3106e-01,\n",
      "          9.7732e-01, -8.4328e-01,  9.2297e-01,  9.4871e-01,  6.3994e-01,\n",
      "         -7.3620e-01,  9.0957e-02, -9.7607e-01, -1.9115e-01, -8.1717e-01,\n",
      "         -9.7907e-01,  3.1635e-01, -7.2013e-01,  1.6124e-01,  5.1998e-02,\n",
      "         -8.9102e-01,  2.3002e-01,  9.9967e-01,  1.1504e-02,  1.1176e-01,\n",
      "         -3.5556e-01, -1.0000e+00,  2.8487e-01, -8.3339e-01,  8.0987e-01,\n",
      "          7.4664e-01,  6.2762e-01,  1.9847e-01,  4.5185e-01,  4.7242e-01,\n",
      "         -3.9164e-03, -1.0570e-01,  9.3340e-02, -1.8906e-01, -5.1946e-01,\n",
      "         -5.7823e-01,  2.8046e-01, -8.2281e-01, -8.9764e-01,  9.1890e-01,\n",
      "          7.4117e-01, -5.9993e-02, -3.1655e-01,  2.8228e-03, -1.4652e-01,\n",
      "          9.0953e-01,  2.5587e-01,  5.4493e-02, -8.4187e-01,  5.7771e-01,\n",
      "          2.4804e-01, -6.1732e-01,  1.0000e+00, -6.4891e-01, -9.5425e-01,\n",
      "          5.5482e-01,  6.8866e-01,  5.5711e-01, -3.3463e-01,  4.7904e-01,\n",
      "         -1.0000e+00,  3.4198e-01, -1.1332e-01, -9.7818e-01,  2.2888e-01,\n",
      "          4.5161e-01, -1.5720e-01,  1.6195e-01,  5.1240e-01, -5.7138e-01,\n",
      "         -3.7296e-01, -2.8502e-01, -8.0263e-01, -2.1937e-01, -2.2406e-01,\n",
      "         -5.1869e-03, -2.6417e-01, -2.2839e-01, -3.7414e-01,  2.6933e-01,\n",
      "         -4.5077e-01, -5.5173e-01,  4.8430e-01,  4.7178e-02,  6.6727e-01,\n",
      "          3.3201e-01, -2.9447e-01,  5.0653e-01, -9.4933e-01,  6.1857e-01,\n",
      "         -2.4586e-01, -9.7565e-01, -5.3396e-01, -9.7924e-01,  5.8934e-01,\n",
      "         -2.3402e-01, -2.7536e-01,  9.4687e-01,  1.5282e-01,  3.0224e-01,\n",
      "          1.1186e-02, -7.3234e-01, -1.0000e+00, -6.9951e-01, -5.0531e-01,\n",
      "         -2.7527e-01, -2.0676e-01, -9.5607e-01, -9.1109e-01,  5.1232e-01,\n",
      "          9.3519e-01,  1.3547e-01,  9.9877e-01, -2.0620e-01,  9.2237e-01,\n",
      "         -4.9195e-01, -7.0814e-01,  6.5991e-01, -4.0702e-01,  7.4080e-01,\n",
      "          4.4237e-01, -6.9697e-01,  1.7959e-01, -2.0311e-01,  2.8031e-01,\n",
      "         -6.5004e-01, -2.2036e-01, -6.8982e-01, -9.2266e-01, -3.2942e-01,\n",
      "          9.3754e-01, -4.7618e-01, -8.9325e-01, -1.4759e-01, -1.4892e-01,\n",
      "         -5.3520e-01,  8.4738e-01,  7.0655e-01,  3.8488e-01, -4.0430e-01,\n",
      "          3.9195e-01,  2.2351e-01,  5.5196e-01, -8.1159e-01, -1.8874e-01,\n",
      "          3.3696e-01, -3.6883e-01, -6.5580e-01, -9.7058e-01, -3.4790e-01,\n",
      "          4.8676e-01,  9.8414e-01,  7.1667e-01,  2.3032e-01,  7.0561e-01,\n",
      "         -8.2327e-02,  7.3910e-01, -9.2162e-01,  9.5893e-01, -3.3638e-01,\n",
      "          2.3401e-01,  6.1110e-02,  4.1919e-01, -8.5576e-01,  1.5276e-01,\n",
      "          8.8090e-01, -6.3311e-01, -8.3712e-01,  6.5171e-02, -4.3054e-01,\n",
      "         -3.4557e-01, -5.9076e-01,  5.1503e-01, -2.6207e-01, -2.4693e-01,\n",
      "          6.1307e-02,  8.7691e-01,  9.8752e-01,  8.0232e-01,  1.4752e-01,\n",
      "          6.8812e-01, -8.9320e-01, -5.4703e-01,  4.8356e-02,  2.1540e-01,\n",
      "          2.3904e-01,  9.9014e-01, -4.9880e-01, -1.3789e-01, -9.2269e-01,\n",
      "         -9.7721e-01, -9.4687e-02, -9.0299e-01, -1.3468e-01, -7.0078e-01,\n",
      "          5.1664e-01,  2.4403e-01,  6.1268e-01,  3.6200e-01, -9.9236e-01,\n",
      "         -7.4132e-01,  3.4922e-01, -2.3057e-01,  3.8191e-01, -1.6780e-01,\n",
      "          3.9556e-02,  8.9809e-01, -5.3350e-01,  8.3722e-01,  8.8839e-01,\n",
      "         -7.2514e-01, -7.3965e-01,  8.9407e-01, -2.3408e-01,  8.7030e-01,\n",
      "         -5.6373e-01,  9.7425e-01,  8.4706e-01,  8.3270e-01, -8.9631e-01,\n",
      "         -5.6269e-01, -9.0159e-01, -6.9973e-01,  6.1689e-02,  9.8559e-02,\n",
      "          8.7749e-01,  5.6404e-01,  3.4049e-01,  3.7582e-01, -6.7834e-01,\n",
      "          9.9827e-01, -3.3601e-02, -9.2002e-01,  2.7571e-01, -3.0865e-01,\n",
      "         -9.6896e-01,  7.2166e-01,  3.3953e-01, -4.0741e-03, -4.1497e-01,\n",
      "         -6.4642e-01, -9.2770e-01,  9.3160e-01,  6.0920e-02,  9.9071e-01,\n",
      "          4.6196e-02, -9.3994e-01, -6.6822e-01, -8.9785e-01, -3.0716e-01,\n",
      "         -2.0500e-01, -3.8714e-01, -8.1208e-02, -9.4563e-01,  4.3475e-01,\n",
      "          4.1566e-01,  4.9148e-01, -6.9445e-01,  9.9830e-01,  1.0000e+00,\n",
      "          9.3747e-01,  8.9366e-01,  9.2651e-01, -9.9799e-01, -2.9389e-01,\n",
      "          9.9995e-01, -9.7730e-01, -1.0000e+00, -9.1234e-01, -6.9568e-01,\n",
      "          3.7277e-01, -1.0000e+00, -2.0609e-01,  1.7125e-01, -8.7448e-01,\n",
      "          5.9412e-01,  9.6720e-01,  9.9095e-01, -1.0000e+00,  6.5990e-01,\n",
      "          9.2648e-01, -6.0201e-01,  9.5347e-01, -3.2178e-01,  9.5794e-01,\n",
      "          6.5932e-01,  1.1768e-01, -2.4565e-01,  3.2490e-01, -8.8230e-01,\n",
      "         -8.7855e-01, -4.5894e-01, -6.2306e-01,  9.8882e-01,  1.1127e-01,\n",
      "         -8.1504e-01, -8.9768e-01, -2.5663e-02, -2.0069e-01, -3.3576e-01,\n",
      "         -9.4615e-01, -1.0597e-01,  5.6197e-01,  7.7034e-01,  9.0875e-02,\n",
      "          3.0440e-01, -6.8938e-01,  2.5243e-01, -1.7008e-01,  3.3678e-01,\n",
      "          6.2607e-01, -9.2541e-01, -6.4668e-01, -4.1812e-01, -1.5776e-01,\n",
      "         -5.8090e-01, -9.3592e-01,  9.5067e-01, -4.7707e-01,  7.9794e-01,\n",
      "          1.0000e+00,  1.2838e-01, -8.6789e-01,  6.2421e-01,  2.0468e-01,\n",
      "          4.3405e-03,  1.0000e+00,  7.7308e-01, -9.5914e-01, -4.9383e-01,\n",
      "          5.1447e-01, -5.0643e-01, -4.6023e-01,  9.9656e-01, -2.7889e-01,\n",
      "         -6.0374e-01, -3.1379e-01,  9.4870e-01, -9.7579e-01,  9.8235e-01,\n",
      "         -8.9237e-01, -9.4238e-01,  9.3981e-01,  9.0497e-01, -6.8348e-01,\n",
      "         -4.2984e-01,  1.2406e-01, -6.3880e-01,  3.0334e-01, -9.6749e-01,\n",
      "          7.3108e-01,  5.1503e-01,  4.4069e-02,  8.4879e-01, -9.0855e-01,\n",
      "         -4.6638e-01,  2.9909e-01, -7.3568e-01, -2.1431e-01,  7.7439e-01,\n",
      "          5.1014e-01, -3.0549e-01,  9.3043e-02, -3.4041e-01,  2.4432e-01,\n",
      "         -9.6357e-01,  3.4927e-01,  1.0000e+00, -2.4683e-01,  4.8418e-01,\n",
      "         -5.1474e-01,  5.1816e-02, -1.7388e-01,  4.7761e-01,  5.5868e-01,\n",
      "         -2.4163e-01, -8.0916e-01,  7.3723e-01, -9.7524e-01, -9.7020e-01,\n",
      "          8.5261e-01,  1.8727e-01, -2.7090e-01,  9.9998e-01,  4.6983e-01,\n",
      "          9.6979e-02,  3.6851e-01,  9.7414e-01, -8.3755e-04,  6.4376e-01,\n",
      "          8.7053e-01,  9.6059e-01, -1.8756e-01,  5.1957e-01,  8.7386e-01,\n",
      "         -8.3668e-01, -2.7663e-01, -5.9559e-01, -1.2339e-02, -8.8570e-01,\n",
      "          8.2444e-02, -9.3376e-01,  9.5201e-01,  8.6130e-01,  3.3720e-01,\n",
      "          2.3967e-01,  5.4095e-01,  1.0000e+00,  1.3089e-01,  7.5866e-01,\n",
      "         -6.5313e-01,  9.1302e-01, -9.9812e-01, -8.6791e-01, -3.1752e-01,\n",
      "         -9.1606e-03, -7.3271e-01, -3.1350e-01,  2.6582e-01, -9.5944e-01,\n",
      "          7.4126e-01,  4.9215e-01, -9.9320e-01, -9.8625e-01, -2.1465e-01,\n",
      "          9.0425e-01, -4.9062e-02, -9.3739e-01, -7.3878e-01, -5.6868e-01,\n",
      "          5.5593e-01, -2.0358e-01, -9.3490e-01, -1.9005e-01, -2.3025e-01,\n",
      "          4.5899e-01, -7.0443e-02,  5.4063e-01,  7.6846e-01,  5.9393e-01,\n",
      "         -1.9536e-01, -1.4414e-01, -2.6515e-02, -8.3050e-01,  8.8996e-01,\n",
      "         -8.3560e-01, -8.2514e-01, -1.7632e-01,  1.0000e+00, -5.3209e-01,\n",
      "          7.4747e-01,  7.9880e-01,  8.0815e-01, -1.0571e-01,  9.6487e-02,\n",
      "          8.7753e-01,  2.1673e-01, -7.5100e-01, -8.1242e-01, -9.0104e-01,\n",
      "         -3.2831e-01,  6.3693e-01,  8.2349e-03,  5.5376e-01,  7.1281e-01,\n",
      "          6.4975e-01,  1.4424e-01,  3.0208e-02, -1.5367e-01,  9.9958e-01,\n",
      "         -2.4823e-01, -4.5267e-02, -4.9861e-01,  8.4451e-03, -3.3764e-01,\n",
      "         -7.4455e-01,  1.0000e+00,  2.2909e-01,  3.0400e-01, -9.8225e-01,\n",
      "         -7.7581e-01, -9.3825e-01,  9.9999e-01,  8.0493e-01, -6.9461e-01,\n",
      "          6.7583e-01,  7.1560e-01, -7.5956e-02,  8.8280e-01, -8.8796e-02,\n",
      "         -3.6776e-01,  3.0358e-01,  9.0578e-02,  9.3570e-01, -5.4713e-01,\n",
      "         -9.4064e-01, -5.1854e-01,  3.6407e-01, -9.4587e-01,  9.9884e-01,\n",
      "         -4.6634e-01, -2.2036e-01, -4.2909e-01,  1.9812e-01,  8.0296e-01,\n",
      "         -1.1237e-01, -9.7593e-01,  3.2543e-03,  2.2387e-01,  9.4407e-01,\n",
      "          2.3152e-01, -5.3741e-01, -9.0152e-01,  7.2972e-01,  6.4678e-01,\n",
      "         -8.5261e-01, -9.2280e-01,  9.4217e-01, -9.8578e-01,  6.6755e-01,\n",
      "          1.0000e+00,  3.4225e-01, -1.6761e-01,  7.7093e-02, -3.9836e-01,\n",
      "          2.2625e-01, -2.2041e-01,  7.3612e-01, -9.2743e-01, -3.6491e-01,\n",
      "         -1.7540e-01,  2.9468e-01, -1.1303e-01,  2.6401e-01,  6.9200e-01,\n",
      "          1.5430e-01, -4.0083e-01, -5.2640e-01,  2.4087e-02,  4.3949e-01,\n",
      "          8.6077e-01, -2.6866e-01, -1.0388e-01,  7.5587e-03, -1.2241e-01,\n",
      "         -9.1376e-01, -2.1348e-01, -2.9673e-01, -9.9988e-01,  6.9455e-01,\n",
      "         -1.0000e+00,  2.8368e-01,  8.6734e-02, -1.2220e-01,  7.9206e-01,\n",
      "          1.5489e-02,  4.9311e-01, -7.3105e-01, -8.1444e-01,  5.0827e-01,\n",
      "          7.2358e-01, -2.9349e-01, -5.1790e-01, -6.9774e-01,  2.4637e-01,\n",
      "         -1.5526e-02,  2.1339e-01, -5.1806e-01,  7.8137e-01, -1.7301e-01,\n",
      "          1.0000e+00,  1.9527e-01, -7.5410e-01, -9.8262e-01,  1.5416e-01,\n",
      "         -2.1457e-01,  1.0000e+00, -9.3285e-01, -9.1573e-01,  2.9430e-01,\n",
      "         -6.9617e-01, -8.3260e-01,  2.6820e-01, -3.4682e-02, -7.8862e-01,\n",
      "         -8.5820e-01,  9.5101e-01,  9.4690e-01, -5.5200e-01,  4.5879e-01,\n",
      "         -3.4441e-01, -5.6057e-01, -4.5147e-02,  7.0248e-01,  9.7133e-01,\n",
      "          2.6254e-01,  8.9137e-01,  4.2302e-01, -7.3707e-02,  9.4970e-01,\n",
      "          1.6445e-01,  6.1382e-01,  1.0270e-01,  1.0000e+00,  2.7983e-01,\n",
      "         -8.8676e-01,  1.4404e-01, -9.7244e-01, -1.6864e-01, -9.5221e-01,\n",
      "          2.6231e-01,  2.7997e-01,  8.9316e-01, -2.3383e-01,  9.4295e-01,\n",
      "         -5.3833e-01,  4.3593e-02, -7.9243e-01, -3.1933e-01,  3.5616e-01,\n",
      "         -9.0270e-01, -9.7206e-01, -9.7301e-01,  6.8435e-01, -4.2106e-01,\n",
      "          4.4723e-02,  1.2440e-01,  7.1746e-03,  3.5916e-01,  4.4393e-01,\n",
      "         -1.0000e+00,  9.2962e-01,  3.8557e-01,  8.5492e-01,  9.2992e-01,\n",
      "          7.0625e-01,  4.8370e-01,  2.3270e-01, -9.7541e-01, -9.8218e-01,\n",
      "         -3.2932e-01, -2.1163e-01,  7.5084e-01,  6.3202e-01,  8.8856e-01,\n",
      "          4.3251e-01, -5.0404e-01, -6.7029e-02, -2.9505e-01, -3.2807e-01,\n",
      "         -9.8568e-01,  4.3446e-01, -5.8658e-01, -9.7724e-01,  9.3651e-01,\n",
      "         -1.3708e-01, -1.3665e-01, -9.2903e-02, -6.6635e-01,  9.7278e-01,\n",
      "          7.0707e-01,  4.3204e-01,  8.7915e-02,  4.7217e-01,  8.3990e-01,\n",
      "          9.4993e-01,  9.7219e-01, -6.7202e-01,  8.3279e-01, -5.4167e-01,\n",
      "          4.1125e-01,  3.4719e-01, -9.0791e-01,  9.1833e-02,  2.0506e-01,\n",
      "         -2.8610e-01,  1.5352e-01, -1.1304e-01, -9.8395e-01,  1.8631e-01,\n",
      "         -2.0863e-01,  6.1166e-01, -2.9382e-01,  5.8579e-02, -3.7076e-01,\n",
      "         -3.7402e-02, -6.2659e-01, -7.5935e-01,  5.6508e-01,  5.0258e-01,\n",
      "          8.7703e-01,  8.0735e-01, -6.9027e-02, -6.4556e-01, -2.2308e-01,\n",
      "         -7.0203e-01, -8.9239e-01,  9.4453e-01, -2.7452e-02, -3.4130e-01,\n",
      "          5.0977e-01, -1.5005e-01,  5.0155e-01,  9.2491e-02, -3.1371e-01,\n",
      "         -3.9861e-01, -6.5197e-01,  8.3609e-01,  4.2015e-02, -5.3505e-01,\n",
      "         -7.0400e-01,  5.6731e-01,  3.1090e-01,  9.9974e-01, -6.7131e-01,\n",
      "         -8.3116e-01, -1.6593e-01, -3.9197e-01,  2.8166e-01, -4.2960e-01,\n",
      "         -1.0000e+00,  3.9846e-01, -3.7210e-01,  6.3236e-01, -6.8413e-01,\n",
      "          4.8827e-01, -7.2434e-01, -9.8220e-01, -1.6253e-01,  4.2167e-02,\n",
      "          6.8658e-01, -4.7085e-01, -7.6191e-01,  4.8094e-01, -1.6689e-01,\n",
      "          9.5317e-01,  8.1554e-01, -3.6865e-01,  1.1302e-01,  6.0376e-01,\n",
      "         -6.5595e-01, -6.1998e-01,  9.0952e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model = onnx.load(\"./models/bert-base/bert-base-cased.onnx\")\n",
    "oldnodes = [n for n in model.graph.node]\n",
    "newnodes = oldnodes[0:125]\n",
    "for n in model.graph.node:\n",
    "    model.graph.node.remove(n)\n",
    "model.graph.node.extend(newnodes)\n",
    "onnx.save(model, \"./models_out/bert-1-v2.onnx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "graph = helper.GraphProto()\n",
    "graph.node.extend(newnodes)\n",
    "model_def = helper.make_model(graph, producer_name='onnx-example')\n",
    "onnx.save(model_def, \"./models_out/bert-1-v3.onnx\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "graph_def = helper.make_graph(\n",
    "            ['Mul_123'],\n",
    "            'Mul_123',\n",
    "            inputs=['A','B'],  # 输入\n",
    "            outputs=['C'],  # 输出\n",
    "            )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Not a cmessage",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-96b6384d46f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'Mul_123'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 输入\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/onnx/helper.py\u001b[0m in \u001b[0;36mmake_graph\u001b[0;34m(nodes, name, inputs, outputs, initializer, doc_string, value_info, sparse_initializer)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mvalue_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Not a cmessage"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = onnx.load(\"./models/vgg16.onnx\")\n",
    "for i in range(20):\n",
    "    print(model.graph.initializer[i].dims)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[512, 512]\n",
      "[512]\n",
      "[512, 512]\n",
      "[512]\n",
      "[10, 512]\n",
      "[10]\n",
      "[64, 3, 3, 3]\n",
      "[64]\n",
      "[64, 64, 3, 3]\n",
      "[64]\n",
      "[128, 64, 3, 3]\n",
      "[128]\n",
      "[128, 128, 3, 3]\n",
      "[128]\n",
      "[256, 128, 3, 3]\n",
      "[256]\n",
      "[256, 256, 3, 3]\n",
      "[256]\n",
      "[256, 256, 3, 3]\n",
      "[256]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "input_path = './models/vgg16.onnx'\n",
    "output_path = './models_out/vgg16_out.onnx'\n",
    "input_names = ['100']\n",
    "output_names = ['121']\n",
    "onnx.utils.extract_model(input_path, output_path, input_names, output_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "input_path = './models/bert-base/bert-base-cased.onnx'\n",
    "output_path = './models_out/bert_out.onnx'\n",
    "# input_names = ['input_ids', 'attention_mask', 'token_type_ids']\n",
    "input_names = ['235']\n",
    "output_names = ['351']\n",
    "onnx.utils.extract_model(input_path, output_path, input_names, output_names)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValidationError",
     "evalue": "Field 'shape' of type is required but missing.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae5cc5817476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'235'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'351'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/onnx/utils.py\u001b[0m in \u001b[0;36mextract_model\u001b[0;34m(input_path, output_path, input_names, output_names)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/onnx/checker.py\u001b[0m in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: (Union[ModelProto, Text], bool) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: Field 'shape' of type is required but missing."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = onnx.load(\"./models/bert-base/bert-base-cased.onnx\")\n",
    "onnx.checker.check_model(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class Extractor:\n",
    "    def __init__(self, model):  # type: (ModelProto) -> None\n",
    "        self.model = onnx.shape_inference.infer_shapes(model)\n",
    "        self.graph = self.model.graph\n",
    "        self.wmap = self._build_name2obj_dict(self.graph.initializer)\n",
    "        self.vimap = self._build_name2obj_dict(self.graph.value_info)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_name2obj_dict(objs):  # type: ignore\n",
    "        return {obj.name: obj for obj in objs}\n",
    "\n",
    "    def _collect_new_io_core(self, original_io, io_names_to_extract):  # type: ignore\n",
    "        original_io_map = self._build_name2obj_dict(original_io)\n",
    "        original_io_names = set(original_io_map.keys())\n",
    "        s_io_names_to_extract = set(io_names_to_extract)\n",
    "        io_names_to_keep = s_io_names_to_extract & original_io_names\n",
    "        new_io_names_to_add = s_io_names_to_extract - original_io_names\n",
    "\n",
    "        new_io_tensors = []\n",
    "        for name in io_names_to_keep:\n",
    "            new_io_tensors.append(original_io_map[name])\n",
    "        for name in new_io_names_to_add:\n",
    "            # activation become input or output\n",
    "            new_io_tensors.append(self.vimap[name])\n",
    "\n",
    "        # adjust sequence\n",
    "        new_io_tensors_map = self._build_name2obj_dict(new_io_tensors)\n",
    "        return [new_io_tensors_map[name] for name in io_names_to_extract]\n",
    "\n",
    "    def _collect_new_inputs(self, names):  # type: (List[Text]) -> List[ValueInfoProto]\n",
    "        return self._collect_new_io_core(self.graph.input, names)  # type: ignore\n",
    "\n",
    "    def _collect_new_outputs(self, names):  # type: (List[Text]) -> List[ValueInfoProto]\n",
    "        return self._collect_new_io_core(self.graph.output, names)  # type: ignore\n",
    "\n",
    "    def _dfs_search_reachable_nodes(\n",
    "            self,\n",
    "            node_output_name,  # type: Text\n",
    "            graph_input_names,  # type: List[Text]\n",
    "            reachable_nodes,  # type: List[NodeProto]\n",
    "    ):  # type: (...) -> None\n",
    "        if node_output_name in graph_input_names:\n",
    "            return\n",
    "        for node in self.graph.node:\n",
    "            if node in reachable_nodes:\n",
    "                continue\n",
    "            if node_output_name not in node.output:\n",
    "                continue\n",
    "            reachable_nodes.append(node)\n",
    "            for name in node.input:\n",
    "                self._dfs_search_reachable_nodes(name, graph_input_names, reachable_nodes)\n",
    "\n",
    "    def _collect_reachable_nodes(\n",
    "            self,\n",
    "            input_names,  # type: List[Text]\n",
    "            output_names,  # type: List[Text]\n",
    "    ):  # type: (...) -> List[NodeProto]\n",
    "        reachable_nodes = list()  # type: ignore\n",
    "        for name in output_names:\n",
    "            self._dfs_search_reachable_nodes(name, input_names, reachable_nodes)\n",
    "        # needs to be topology sorted.\n",
    "        nodes = [n for n in self.graph.node if n in reachable_nodes]\n",
    "        return nodes\n",
    "\n",
    "    def _collect_reachable_tensors(\n",
    "            self,\n",
    "            nodes,  # type: List[NodeProto]\n",
    "    ):  # type: (...) -> Tuple[List[TensorProto], List[ValueInfoProto]]\n",
    "        all_tensors_name = set()\n",
    "        for node in nodes:\n",
    "            for name in node.input:\n",
    "                all_tensors_name.add(name)\n",
    "            for name in node.output:\n",
    "                all_tensors_name.add(name)\n",
    "\n",
    "        initializer = [self.wmap[t] for t in self.wmap.keys() if t in all_tensors_name]\n",
    "        value_info = [self.vimap[t] for t in self.vimap.keys() if t in all_tensors_name]\n",
    "        assert(len(self.graph.sparse_initializer) == 0)\n",
    "        assert(len(self.graph.quantization_annotation) == 0)\n",
    "        return (initializer, value_info)\n",
    "\n",
    "    def _make_model(\n",
    "            self,\n",
    "            nodes,  # type: List[NodeProto]\n",
    "            inputs,  # type: List[ValueInfoProto]\n",
    "            outputs,  # type: List[ValueInfoProto]\n",
    "            initializer,  # type: List[TensorProto]\n",
    "            value_info  # type: List[ValueInfoProto]\n",
    "    ):  # type: (...) -> ModelProto\n",
    "        name = 'Extracted from {' + self.graph.name + '}'\n",
    "        graph = onnx.helper.make_graph(nodes, name, inputs, outputs, initializer=initializer,\n",
    "                                      value_info=value_info)\n",
    "\n",
    "        meta = {\n",
    "            'ir_version': self.model.ir_version,\n",
    "            'opset_imports': self.model.opset_import,\n",
    "            'producer_name': 'onnx.utils.extract_model',\n",
    "        }\n",
    "        return onnx.helper.make_model(graph, **meta)\n",
    "\n",
    "    def extract_model(\n",
    "            self,\n",
    "            input_names,  # type: List[Text]\n",
    "            output_names,  # type: List[Text]\n",
    "    ):  # type: (...) -> ModelProto\n",
    "        inputs = self._collect_new_inputs(input_names)\n",
    "        outputs = self._collect_new_outputs(output_names)\n",
    "        nodes = self._collect_reachable_nodes(input_names, output_names)\n",
    "        initializer, value_info = self._collect_reachable_tensors(nodes)\n",
    "        model = self._make_model(nodes, inputs, outputs, initializer, value_info)\n",
    "\n",
    "        return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "input_path = './models/bert-base/bert-base-cased.onnx'\n",
    "output_path = './models_out/bert_out.onnx'\n",
    "input_names = ['235']\n",
    "output_names = ['351']\n",
    "onnx.checker.check_model(input_path)\n",
    "model = onnx.load(input_path)\n",
    "\n",
    "e = Extractor(model)\n",
    "extracted = e.extract_model(input_names, output_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "onnx.save(extracted, output_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "extracted = onnx.shape_inference.infer_shapes(extracted)\n",
    "onnx.save(extracted, './models_out/bert_out_2.onnx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "! mkdir ./models/bert-text-classification"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from pathlib import Path\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "\n",
    "# Handles all the above steps for you\n",
    "p = {\"num_labels\": 2}\n",
    "convert(framework=\"pt\", model=\"bert-base-cased\", output=Path(\"./models/bert-text-classification/bert-cls.onnx\"), opset=11, pipeline_name=\"text-classification\", **p)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ONNX opset version set to: 11\n",
      "Loading pipeline (model: bert-base-cased, tokenizer: bert-base-cased)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using framework PyTorch: 1.8.0\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/modeling_utils.py:1974: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import list_datasets\n",
    "datasets_list = list_datasets()\n",
    "len(datasets_list)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "raw_datasets = load_dataset(\"imdb\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92c0261f6959463b9a8aa782dc08dfac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0dd570b457f4fcf9ffa531dd8dbea4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 80.23 MiB, generated: 127.02 MiB, post-processed: Unknown size, total: 207.25 MiB) to /home/slzhang/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "107c384104574225a90061cb3d1254a7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec01da09ef5341dd9cb372dd87372373"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afa3c1e6588c488ea6ed413b6480ea5a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53099a3256844a498dc8b2213fe68f62"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset imdb downloaded and prepared to /home/slzhang/.cache/huggingface/datasets/imdb/plain_text/1.0.0/e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdede0c682e743829122695d0c7de6eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05c9c316ed3c4baa8da38bc900dfcd6c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "003fd86c5b924280992f2728632ed249"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000)) \n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000)) \n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: greenlet.greenlet size changed, may indicate binary incompatibility. Expected 144 from C header, got 152 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzsl\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.11.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">test_trainer</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/zsl/huggingface\" target=\"_blank\">https://wandb.ai/zsl/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/zsl/huggingface/runs/3mz33giu\" target=\"_blank\">https://wandb.ai/zsl/huggingface/runs/3mz33giu</a><br/>\n",
       "                Run data is saved locally in <code>/home/slzhang/projects/ETBA/ModelSplit/wandb/run-20210806_170126-3mz33giu</code><br/><br/>\n",
       "            "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/home/slzhang/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/375 00:50 < 44:15, 0.14 it/s, Epoch 0.06/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1752\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1786\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         )\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m         )\n\u001b[1;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         )\n\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/transformers-4.8.1-py3.8.egg/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/fedml/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('fedml': conda)"
  },
  "interpreter": {
   "hash": "974ac649167fefaf253379c48dc7b4aaed194fc33f94bc0767d802e4d67b73ad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}