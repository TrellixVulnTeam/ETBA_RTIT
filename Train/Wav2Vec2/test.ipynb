{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import soundfile as sf\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2FeatureExtractor, Wav2Vec2CTCTokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84dd02845fd5499189e80651637c438f"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89047b49d777424a9438c081f9d29f9f"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e612eceab747478d9fdc1bba468e6a09"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de8d47c51a2545ecb917c50ab29286ed"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "143f5d2bd3fa4dc8925521edb676f5d3"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41624e16a6e641b9a0e69a47faeae4bf"
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "librispeech_samples_ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "# load audio\n",
    "audio_input, sample_rate = sf.read(librispeech_samples_ds[2][\"file\"])\n",
    "\n",
    "# pad input values and return pt tensor\n",
    "input_values = processor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "\n",
    "# INFERENCE\n",
    "\n",
    "# retrieve logits & take argmax\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# transcribe\n",
    "transcription = processor.decode(predicted_ids[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset librispeech_asr (/home/slzhang/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# FINE-TUNE\n",
    "\n",
    "target_transcription = \"A MAN SAID TO THE UNIVERSE\"\n",
    "\n",
    "# encode labels\n",
    "with processor.as_target_processor():\n",
    "  labels = processor(target_transcription, return_tensors=\"pt\").input_ids"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "predicted_ids.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 624])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "input_values.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 199760])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "decoder = Wav2Vec2CTCTokenizer\n",
    "input_values = extractor(audio_input, sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = decoder.decode(predicted_ids[0])\n",
    "transcription\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "decode() missing 1 required positional argument: 'token_ids'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1180294733cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: decode() missing 1 required positional argument: 'token_ids'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "predicted_ids[0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([624])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "dummy_input = torch.randn(500)\n",
    "torch.onnx.export(decoder.decode(), dummy_input, \"./Wav2Vec_decoder.onnx\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "decode() missing 1 required positional argument: 'token_ids'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-e0de49488dce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./Wav2Vec_decoder.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: decode() missing 1 required positional argument: 'token_ids'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "for k,v in model.named_parameters():\n",
    "    print(k)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wav2vec2.masked_spec_embed\n",
      "wav2vec2.feature_extractor.conv_layers.0.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.0.layer_norm.weight\n",
      "wav2vec2.feature_extractor.conv_layers.0.layer_norm.bias\n",
      "wav2vec2.feature_extractor.conv_layers.1.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.2.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.3.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.4.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.5.conv.weight\n",
      "wav2vec2.feature_extractor.conv_layers.6.conv.weight\n",
      "wav2vec2.feature_projection.layer_norm.weight\n",
      "wav2vec2.feature_projection.layer_norm.bias\n",
      "wav2vec2.feature_projection.projection.weight\n",
      "wav2vec2.feature_projection.projection.bias\n",
      "wav2vec2.encoder.pos_conv_embed.conv.bias\n",
      "wav2vec2.encoder.pos_conv_embed.conv.weight_g\n",
      "wav2vec2.encoder.pos_conv_embed.conv.weight_v\n",
      "wav2vec2.encoder.layer_norm.weight\n",
      "wav2vec2.encoder.layer_norm.bias\n",
      "wav2vec2.encoder.layers.0.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.0.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.0.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.0.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.0.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.0.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.0.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.0.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.0.layer_norm.weight\n",
      "wav2vec2.encoder.layers.0.layer_norm.bias\n",
      "wav2vec2.encoder.layers.0.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.0.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.0.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.0.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.0.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.0.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.1.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.1.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.1.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.1.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.1.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.1.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.1.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.1.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.1.layer_norm.weight\n",
      "wav2vec2.encoder.layers.1.layer_norm.bias\n",
      "wav2vec2.encoder.layers.1.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.1.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.1.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.1.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.1.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.1.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.2.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.2.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.2.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.2.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.2.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.2.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.2.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.2.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.2.layer_norm.weight\n",
      "wav2vec2.encoder.layers.2.layer_norm.bias\n",
      "wav2vec2.encoder.layers.2.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.2.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.2.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.2.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.2.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.2.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.3.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.3.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.3.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.3.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.3.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.3.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.3.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.3.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.3.layer_norm.weight\n",
      "wav2vec2.encoder.layers.3.layer_norm.bias\n",
      "wav2vec2.encoder.layers.3.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.3.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.3.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.3.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.3.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.3.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.4.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.4.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.4.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.4.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.4.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.4.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.4.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.4.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.4.layer_norm.weight\n",
      "wav2vec2.encoder.layers.4.layer_norm.bias\n",
      "wav2vec2.encoder.layers.4.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.4.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.4.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.4.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.4.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.4.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.5.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.5.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.5.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.5.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.5.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.5.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.5.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.5.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.5.layer_norm.weight\n",
      "wav2vec2.encoder.layers.5.layer_norm.bias\n",
      "wav2vec2.encoder.layers.5.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.5.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.5.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.5.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.5.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.5.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.6.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.6.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.6.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.6.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.6.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.6.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.6.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.6.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.6.layer_norm.weight\n",
      "wav2vec2.encoder.layers.6.layer_norm.bias\n",
      "wav2vec2.encoder.layers.6.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.6.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.6.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.6.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.6.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.6.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.7.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.7.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.7.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.7.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.7.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.7.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.7.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.7.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.7.layer_norm.weight\n",
      "wav2vec2.encoder.layers.7.layer_norm.bias\n",
      "wav2vec2.encoder.layers.7.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.7.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.7.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.7.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.7.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.7.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.8.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.8.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.8.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.8.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.8.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.8.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.8.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.8.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.8.layer_norm.weight\n",
      "wav2vec2.encoder.layers.8.layer_norm.bias\n",
      "wav2vec2.encoder.layers.8.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.8.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.8.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.8.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.8.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.8.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.9.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.9.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.9.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.9.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.9.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.9.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.9.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.9.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.9.layer_norm.weight\n",
      "wav2vec2.encoder.layers.9.layer_norm.bias\n",
      "wav2vec2.encoder.layers.9.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.9.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.9.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.9.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.9.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.9.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.10.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.10.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.10.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.10.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.10.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.10.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.10.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.10.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.10.layer_norm.weight\n",
      "wav2vec2.encoder.layers.10.layer_norm.bias\n",
      "wav2vec2.encoder.layers.10.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.10.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.10.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.10.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.10.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.10.final_layer_norm.bias\n",
      "wav2vec2.encoder.layers.11.attention.k_proj.weight\n",
      "wav2vec2.encoder.layers.11.attention.k_proj.bias\n",
      "wav2vec2.encoder.layers.11.attention.v_proj.weight\n",
      "wav2vec2.encoder.layers.11.attention.v_proj.bias\n",
      "wav2vec2.encoder.layers.11.attention.q_proj.weight\n",
      "wav2vec2.encoder.layers.11.attention.q_proj.bias\n",
      "wav2vec2.encoder.layers.11.attention.out_proj.weight\n",
      "wav2vec2.encoder.layers.11.attention.out_proj.bias\n",
      "wav2vec2.encoder.layers.11.layer_norm.weight\n",
      "wav2vec2.encoder.layers.11.layer_norm.bias\n",
      "wav2vec2.encoder.layers.11.feed_forward.intermediate_dense.weight\n",
      "wav2vec2.encoder.layers.11.feed_forward.intermediate_dense.bias\n",
      "wav2vec2.encoder.layers.11.feed_forward.output_dense.weight\n",
      "wav2vec2.encoder.layers.11.feed_forward.output_dense.bias\n",
      "wav2vec2.encoder.layers.11.final_layer_norm.weight\n",
      "wav2vec2.encoder.layers.11.final_layer_norm.bias\n",
      "lm_head.weight\n",
      "lm_head.bias\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('fedml': conda)"
  },
  "interpreter": {
   "hash": "974ac649167fefaf253379c48dc7b4aaed194fc33f94bc0767d802e4d67b73ad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}